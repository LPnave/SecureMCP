â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          SecureMCP Agent UI - Quick Start Guide             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ PREREQUISITES:
   âœ“ Python 3.9+
   âœ“ Node.js 18+
   âœ“ GPT-OSS Docker running (e.g., http://localhost:8080)

ğŸš€ START IN 3 STEPS:

1ï¸âƒ£  PYTHON BACKEND:
   cd agent-ui/python-backend
   pip install -r requirements.txt
   python -m spacy download en_core_web_sm
   
   # Create .env file:
   GPT_OSS_URL=http://localhost:8080/v1/chat/completions
   
   python -m app.main

2ï¸âƒ£  FRONTEND:
   cd agent-ui/secure_agent
   npm install
   npm run dev

3ï¸âƒ£  TEST:
   Open: http://localhost:3000
   Type: "Hello, what can you help me with?"

ğŸ” VERIFY SETUP:

   Backend Health:
   curl http://localhost:8003/api/health

   GPT-OSS Connection:
   curl http://localhost:8080/v1/models

ğŸ› ï¸  CONFIGURATION:

   Python Backend (.env):
   - PORT=8003
   - GPT_OSS_URL=http://localhost:8080/v1/chat/completions
   - GPT_OSS_MODEL=gpt-3.5-turbo
   - DEFAULT_SECURITY_LEVEL=medium

   Frontend (.env.local):
   - NEXT_PUBLIC_SANITIZER_API_URL=http://localhost:8003

ğŸ“Š ARCHITECTURE:

   Frontend â†’ Python Backend â†’ GPT-OSS
   (Next.js)  (Sanitization)    (AI Model)

ğŸ”’ SECURITY FLOW:

   1. User sends message
   2. Backend sanitizes prompt (Zero-shot ML)
   3. Sanitized prompt â†’ GPT-OSS
   4. AI response â†’ User

âš¡ COMMON ISSUES:

   âŒ "Cannot connect to AI model"
   â†’ Check GPT_OSS_URL in .env
   â†’ Verify Docker is running: docker ps

   âŒ "ModuleNotFoundError: No module named 'app'"
   â†’ Run from python-backend/ directory
   â†’ Use: python -m app.main

   âŒ 422 or 503 errors
   â†’ Check backend is running: curl localhost:8003/api/health
   â†’ Check CORS_ORIGINS in .env

ğŸ“š FULL DOCS: See SETUP_GUIDE.md

ğŸ‰ You're all set! Happy chatting with secure AI!

